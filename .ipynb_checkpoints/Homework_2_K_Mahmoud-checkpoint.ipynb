{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  \n",
    "> a. $$Gini = 1 - \\sum_{i=0}^n p_i^2  = 1 - \\frac{10^2} {20^2} + \\frac{10^2} {20^2} = 1 - \\frac{100 + 100} {400} = \\frac {1} {2} = 0.5$$\n",
    "> b. Customer ID Gini = 0<br/>\n",
    "> c. Gender Gini =  0.48 <br/>\n",
    "> d. Car Type Gini =  0.163 <br/>\n",
    "> e. Shirt Size Gini =  0.4915 <br/>\n",
    "> f. The feature to split on would be Shirt Size.<br/>\n",
    "> g. Cust ID wouldn't be suitable because it would fracture the tree into leaves based on ID. This would overfit our model and wouldn't make sense.\n",
    "3. \n",
    "> a. entropy = 0.991076 <br/>\n",
    "> b. The information gain for **a1** is 0.2294 and for **a2** is 0.0072 <br/>\n",
    "> c. \n",
    ">> Information Gain from 1.0:  0.14269027946047563 <br/>\n",
    ">> Information Gain from 6.0:  0.018310781820059074 <br/>\n",
    ">> Information Gain from 5.0:  0.007214618474517431 <br/>\n",
    ">> Information Gain from 4.0:  0.07278022578373267 <br/>\n",
    ">> Information Gain from 7.0:  0.10218717094933338 <br/>\n",
    ">> Information Gain from 3.0:  0.002565287367137681<br/>\n",
    ">> Information Gain from 8.0:  0.0 <br/>\n",
    "\n",
    "3(cont). \n",
    "> d. **a1** is the best split if we are going by information gain. <br/>\n",
    "> e. **a1** has a smaller misclassification value thus its a better split. <br/>\n",
    "> f. **a1** has a smaller and thus better gini index and it produces purer nodes. <br/>\n",
    "\n",
    "5. \n",
    "> a. attribute A has an informaton gain of 0.2812908992306925, while B has a information gain of 0.256425891682003 a decision tree would choose A. <br/>\n",
    "> b. A has a gini of 0.48979591836734704 and B has  gini index of 0.6527777777777777 thus an tree algorithm would choose A because a has less gini and thus produces purer nodes <br/>\n",
    "> c. It wouldn't be possible that information gain and gini favor different attributes. They both measure how impure the child nodes are and thus they are more symmetrical. It wouldn't make sense that they would choose different variables. <br/>\n",
    "6. \n",
    "> a. The gini index of the parent is 0.42 and the misclassification of the parent is  0.3.<br/>\n",
    "> b. The weighted gini for C1 is 0. The weighted gini for C2 is 0.3428571428571429. Thus the total weighted gini is 0.3428571428571429. This attribute test is better because it is more representative of the over all class proportions. <br/>\n",
    "> c. Weighted misclassification for C1 is 0, for C2 is 0.3. There is almost no difference between misclassification and weighted misclassification. <br/>\n",
    "7. \n",
    "> a. My first split would be with Z. For my second split I would choose X for both of the other nodes. The total error on the tree would 1.0. <br/>\n",
    "> b. I would split the both children nodes with Y. <br/>\n",
    "> c. I would say that split using a greedy algorithm doesn't work out in optimally splitting the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper import my_gini\n",
    "from helper import my_entropy\n",
    "from helper import my_misclass\n",
    "from helper import information_gain\n",
    "from helper import weighted_gini\n",
    "from helper import weighted_misclass\n",
    "from helper import gini_off_col\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data set gini: 0.5\n",
      "Gender gini: 0.48\n",
      "Car Type: 0.16250000000000003\n",
      "Shirt Size: 0.49142857142857144\n"
     ]
    }
   ],
   "source": [
    "exercise_2 = {\"Cust ID\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "              \"Gender\": [\"M\",\"M\",\"M\",\"M\",\"M\",\"M\",\"F\",\"F\",\"F\",\"F\",\"M\",\"M\",\"M\",\"M\",\"F\",\"F\",\"F\",\"F\",\"F\",\"F\"], \n",
    "              \"Car Type\": [\"Family\",\"Sports\",\"Sports\",\"Sports\",\"Sports\",\"Sports\",\"Sports\",\"Sports\",\"Sports\",\"Luxury\",\"Family\",\"Family\",\"Family\",\"Luxury\",\"Luxury\",\"Luxury\",\"Luxury\",\"Luxury\",\"Luxury\",\"Luxury\"],\n",
    "              \"Shirt Size\":[\"Small\",\"Medium\",\"Medium\",\"Large\",\"Extra Large\",\"Extra Large\",\"Small\",\"Small\",\"Medium\",\"Large\",\"Large\",\"Extra Large\",\"Medium\",\"Extra Large\",\"Small\",\"Small\",\"Medium\",\"Medium\",\"Medium\",\"Large\"],\n",
    "              \"Target\":[\"C0\",\"C0\",\"C0\",\"C0\",\"C0\",\"C0\",\"C0\",\"C0\",\"C0\",\"C0\",\"C1\",\"C1\",\"C1\",\"C1\",\"C1\",\"C1\",\"C1\",\"C1\",\"C1\",\"C1\"]}\n",
    "pd_exercise_2 = pd.DataFrame(data=exercise_2)\n",
    "car = []\n",
    "gender = []\n",
    "print(\"Full data set gini:\", my_gini(pd_exercise_2, \"Target\"))\n",
    "print(\"Gender gini:\",gini_off_col(pd_exercise_2, \"Gender\", \"Target\"))\n",
    "print(\"Car Type:\",gini_off_col(pd_exercise_2, \"Car Type\", \"Target\"))\n",
    "print(\"Shirt Size:\", gini_off_col(pd_exercise_2,\"Shirt Size\",\"Target\" ))\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.204793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             a3\n",
       "count  9.000000\n",
       "mean   5.111111\n",
       "std    2.204793\n",
       "min    1.000000\n",
       "25%    4.000000\n",
       "50%    5.000000\n",
       "75%    7.000000\n",
       "max    8.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise_3 = {\"a1\": [True,True,True,False,False,False,False,True,False], \n",
    "              \"a2\": [True,True,False,False,True,True,False,False,True],\n",
    "              \"a3\":[1.0,6.0,5.0,4.0,7.0,3.0,8.0,7.0,5.0], \"Target\":[\"+\",\"+\",\"-\",\"+\",\"-\",\"-\",\"-\",\"+\",\"-\"]}\n",
    "pd_exr_3 = pd.DataFrame(data=exercise_3)\n",
    "pd_exr_3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8112781244591328\n",
      "0.7219280948873623\n",
      "Information Gain from A1:  0.22943684069673975\n"
     ]
    }
   ],
   "source": [
    "a1_split_right = pd_exr_3[pd_exr_3[\"a1\"] == True]\n",
    "a1_split_left = pd_exr_3[pd_exr_3[\"a1\"] == False]\n",
    "print(my_entropy(a1_split_right, \"Target\"))\n",
    "print(my_entropy(a1_split_left, \"Target\"))\n",
    "print(\"Information Gain from A1: \", information_gain(pd_exr_3,a1_split_right,a1_split_left,\"Target\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709505944546686\n",
      "1.0\n",
      "Information Gain from A2:  0.007214618474517431\n"
     ]
    }
   ],
   "source": [
    "a2_split_right = pd_exr_3[pd_exr_3[\"a2\"] == True]\n",
    "a2_split_left = pd_exr_3[pd_exr_3[\"a2\"] == False]\n",
    "print(my_entropy(a2_split_right, \"Target\"))\n",
    "print(my_entropy(a2_split_left, \"Target\"))\n",
    "print(\"Information Gain from A2: \", information_gain(pd_exr_3,a2_split_right,a2_split_left,\"Target\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification of a1: 0.25\n",
      "Misclassification of a2: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Misclassification of a1:\",min(my_misclass(a1_split_right, \"Target\"), my_misclass(a1_split_left, \"Target\")))\n",
    "print(\"Misclassification of a2:\",min(my_misclass(a2_split_right, \"Target\"), my_misclass(a2_split_left, \"Target\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini for a1: 0.6949999999999998\n",
      "Gini for a2: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini for a1:\", my_gini(a1_split_right, \"Target\") + my_gini(a1_split_left, \"Target\"))\n",
    "print(\"Gini for a2:\", my_gini(a2_split_right, \"Target\") + my_gini(a2_split_left, \"Target\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain from 1.0:  0.14269027946047563\n",
      "Information Gain from 6.0:  0.018310781820059074\n",
      "Information Gain from 5.0:  0.007214618474517431\n",
      "Information Gain from 4.0:  0.07278022578373267\n",
      "Information Gain from 7.0:  0.10218717094933338\n",
      "Information Gain from 3.0:  0.002565287367137681\n",
      "Information Gain from 8.0:  0.0\n"
     ]
    }
   ],
   "source": [
    "splitter = []\n",
    "for a in pd_exr_3[\"a3\"]:\n",
    "    if a not in splitter:\n",
    "        splitter.append(a)\n",
    "        r = pd_exr_3[pd_exr_3[\"a3\"] > a]\n",
    "        l = pd_exr_3[pd_exr_3[\"a3\"] <= a]\n",
    "        print(\"Information Gain from \" + str(a) + \": \", information_gain(pd_exr_3,r,l,\"Target\" )) \n",
    "        # THERE IS NOTHING GREATER THAN 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9910760598382222\n"
     ]
    }
   ],
   "source": [
    "print(my_entropy(pd_exr_3, \"Target\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Class Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A      B Class Label\n",
       "count     10     10          10\n",
       "unique     2      2           2\n",
       "top     True  False           -\n",
       "freq       7      6           6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise_5 = {\"A\": [True,True,True,True,True,False,False,False,True, True], \n",
    "              \"B\": [False, True,True,False,True,False,False,False,True,False],\n",
    "             \"Class Label\":[\"+\",\"+\",\"+\",\"-\",\"+\",\"-\",\"-\",\"-\",\"-\",\"-\"]}\n",
    "pd_exr_5 = pd.DataFrame(data=exercise_5)\n",
    "pd_exr_5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info gain for A: 0.2812908992306925\n",
      "Gini index for A: 0.48979591836734704\n"
     ]
    }
   ],
   "source": [
    "right_a_exr_5 = pd_exr_5[pd_exr_5[\"A\"] == True]\n",
    "left_a_exr_5 = pd_exr_5[pd_exr_5[\"A\"] == False]\n",
    "print(\"info gain for A:\", information_gain(pd_exr_5, right_a_exr_5, left_a_exr_5, \"Class Label\"))\n",
    "print(\"Gini index for A:\", my_gini(right_a_exr_5, \"Class Label\") + my_gini(left_a_exr_5, \"Class Label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info gain for B: 0.256425891682003\n",
      "Gini index for B: 0.6527777777777777\n"
     ]
    }
   ],
   "source": [
    "right_b_exr_5 = pd_exr_5[pd_exr_5[\"B\"] == True]\n",
    "left_b_exr_5 = pd_exr_5[pd_exr_5[\"B\"] == False]\n",
    "print(\"info gain for B:\", information_gain(pd_exr_5, right_b_exr_5, left_b_exr_5, \"Class Label\"))\n",
    "print(\"Gini index for B:\", my_gini(right_b_exr_5, \"Class Label\") + my_gini(left_b_exr_5, \"Class Label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini of parent: 0.42000000000000004\n",
      "Misclassification of parent: 0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "exercise_6 = {\"P\":[\"+\",\"+\",\"+\",\"-\",\"-\",\"-\",\"-\",\"-\",\"-\",\"-\"]}\n",
    "pd_exr_6 = pd.DataFrame(data=exercise_6)\n",
    "pd_exr_6.describe()\n",
    "print(\"Gini of parent:\", my_gini(pd_exr_6, \"P\"))\n",
    "print(\"Misclassification of parent:\", my_misclass(pd_exr_6,\"P\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "c1_data = {\"P\":[\"-\", \"-\", \"-\"]}\n",
    "pd_c1 = pd.DataFrame(data=c1_data)\n",
    "print(weighted_gini(pd_exr_6, pd_c1, \"P\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3428571428571429\n"
     ]
    }
   ],
   "source": [
    "c2_data = {\"P\": [\"-\", \"-\", \"-\", \"-\", \"+\", \"+\",\"+\"]}\n",
    "pd_c2 = pd.DataFrame(data=c2_data)\n",
    "print(weighted_gini(pd_exr_6, pd_c2, \"P\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(weighted_misclass(pd_exr_6, pd_c1, \"P\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "print(weighted_misclass(pd_exr_6, pd_c2, \"P\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Class C1 examples</th>\n",
       "      <th>Class C2 examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>15.352989</td>\n",
       "      <td>13.363062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>16.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              X         Y         Z  Class C1 examples  Class C2 examples\n",
       "count  8.000000  8.000000  8.000000           8.000000           8.000000\n",
       "mean   0.500000  0.500000  0.500000          12.500000          12.500000\n",
       "std    0.534522  0.534522  0.534522          15.352989          13.363062\n",
       "min    0.000000  0.000000  0.000000           0.000000           0.000000\n",
       "25%    0.000000  0.000000  0.000000           3.750000           3.750000\n",
       "50%    0.500000  0.500000  0.500000           7.500000          10.000000\n",
       "75%    1.000000  1.000000  1.000000          13.750000          16.250000\n",
       "max    1.000000  1.000000  1.000000          45.000000          40.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise_7 = {\"X\": [0,0,0,0,1,1,1,1],\n",
    "              \"Y\": [0,0,1,1,0,0,1,1],\n",
    "              \"Z\": [0,1,0,1,0,1,0,1],\n",
    "              \"Class C1 examples\": [5, 0, 10, 45, 10,25, 5, 0],\n",
    "              \"Class C2 examples\": [40, 15, 5, 0, 5, 0, 20, 15]\n",
    "              }\n",
    "pd_exr_7 = pd.DataFrame(data=exercise_7)\n",
    "pd_exr_7.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_misclassification(panda, col1, col2):\n",
    "    p = []\n",
    "    p.append(panda[col1].sum()/(panda[col1].sum() + panda[col2].sum()))\n",
    "    p.append(panda[col2].sum()/(panda[col1].sum() + panda[col2].sum()))\n",
    "    return 1 - max(p)\n",
    "exr7_c1, exr7_c2 = \"Class C1 examples\", \"Class C2 examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "false_x = pd_exr_7[pd_exr_7[\"X\"] == 0]\n",
    "true_x = pd_exr_7[pd_exr_7[\"X\"] == 1]\n",
    "print(sum_misclassification(false_x, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(true_x, exr7_c1, exr7_c2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "false_y = pd_exr_7[pd_exr_7[\"Y\"] == 0]\n",
    "true_y = pd_exr_7[pd_exr_7[\"Y\"] == 1]\n",
    "print(sum_misclassification(false_y, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(true_y, exr7_c1, exr7_c2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n",
      "0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "false_z = pd_exr_7[pd_exr_7[\"Z\"] == 0]\n",
    "true_z = pd_exr_7[pd_exr_7[\"Z\"] == 1]\n",
    "print(sum_misclassification(false_z, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(true_z, exr7_c1, exr7_c2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n",
      "0.25\n",
      "0.375\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "z_neg_x_pos = false_z[false_z[\"X\"] == 1]\n",
    "z_neg_x_neg = false_z[false_z[\"X\"] == 0]\n",
    "z_pos_x_pos = true_z[true_z[\"X\"] == 1]\n",
    "z_pos_x_neg = true_z[true_z[\"X\"] == 0]\n",
    "print(sum_misclassification(z_neg_x_pos, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(z_neg_x_neg, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(z_pos_x_pos, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(z_pos_x_neg, exr7_c1, exr7_c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n",
      "0.25\n",
      "0.25\n",
      "0.375\n"
     ]
    }
   ],
   "source": [
    "z_neg_y_pos = false_z[false_z[\"Y\"] == 1]\n",
    "z_neg_y_neg = false_z[false_z[\"Y\"] == 0]\n",
    "z_pos_y_pos = true_z[true_z[\"Y\"] == 1]\n",
    "z_pos_y_neg = true_z[true_z[\"Y\"] == 0]\n",
    "print(sum_misclassification(z_neg_y_pos, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(z_neg_y_neg, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(z_pos_y_pos, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(z_pos_y_neg, exr7_c1, exr7_c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333337\n",
      "0.08333333333333337\n",
      "0.125\n",
      "0.125\n"
     ]
    }
   ],
   "source": [
    "x_neg_y_pos = false_x[false_x[\"Y\"] == 1]\n",
    "x_neg_y_neg = false_x[false_x[\"Y\"] == 0]\n",
    "x_pos_y_pos = true_x[true_x[\"Y\"] == 1]\n",
    "x_pos_y_neg = true_x[true_x[\"Y\"] == 0]\n",
    "print(sum_misclassification(x_neg_y_pos, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(x_neg_y_neg, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(x_pos_y_pos, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(x_pos_y_neg, exr7_c1, exr7_c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.25\n",
      "0.375\n",
      "0.375\n"
     ]
    }
   ],
   "source": [
    "x_neg_z_pos = false_x[false_x[\"Z\"] == 1]\n",
    "x_neg_z_neg = false_x[false_x[\"Z\"] == 0]\n",
    "x_pos_z_pos = true_x[true_x[\"Z\"] == 1]\n",
    "x_pos_z_neg = true_x[true_x[\"Z\"] == 0]\n",
    "print(sum_misclassification(x_neg_z_pos, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(x_neg_z_neg, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(x_pos_z_pos, exr7_c1, exr7_c2))\n",
    "print(sum_misclassification(x_pos_z_neg, exr7_c1, exr7_c2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "*****\n",
    "\n",
    "Load the iris sample dataset from sklearn **loadiris()** into Python using a Pandas dataframe.  Induce a set of binary Decision Trees with a minimum of 2 instances in the leaves, no splits of subsets below 5, and an maximal tree depth from 1 to 5 (you can leave the majority parameter to 95%).  Which depth values result in the highest Recall? Why? Which value resulted in the lowest Precision? Why?  Which value results in the best F1 score?  Explain the difference between the micro/macro/weighted methods of score calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer \n",
    "\n",
    "All depth greater than or equal to 2 have the highest recall. The reason recall improves from depth 1 to depth 2+ is because at depth one we have 2 leafs. Adding more levels allows for leafs to develop that will identify the 3 class. Thus TP increases and so does Recall. The lowest precision was with depth 1, because there was a large number of FP. The best f-score is for 2+. The Macro method takes the average of all scores from different classes. Micro takes the ratio of the overall classifier using all the classes information. Weighted calculation looks at the individual calculations of metrics in each class but sums them based on weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)     species  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "pd_iris = pd.DataFrame(data = np.c_[iris.data, iris.target], columns = iris.feature_names+['species'])\n",
    "\n",
    "pd_iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, target_train, target_test = model_selection.train_test_split(iris.data,\n",
    "                                                                    iris.target,\n",
    "                                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Tree with depth: 1 -----------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       0.45      1.00      0.62        10\n",
      "\n",
      "   micro avg       0.60      0.60      0.60        30\n",
      "   macro avg       0.48      0.67      0.54        30\n",
      "weighted avg       0.42      0.60      0.47        30\n",
      "\n",
      "----------------------------Confusion Matrix---------------------------\n",
      "\n",
      "[[ 8  0  0]\n",
      " [ 0  0 12]\n",
      " [ 0  0 10]]\n",
      "\n",
      "----------------------------Tree with depth: 2 -----------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.92      0.92      0.92        12\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        30\n",
      "   macro avg       0.94      0.94      0.94        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "----------------------------Confusion Matrix---------------------------\n",
      "\n",
      "[[ 8  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  1  9]]\n",
      "\n",
      "----------------------------Tree with depth: 3 -----------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      0.92      0.96        12\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "----------------------------Confusion Matrix---------------------------\n",
      "\n",
      "[[ 8  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0 10]]\n",
      "\n",
      "----------------------------Tree with depth: 4 -----------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "----------------------------Confusion Matrix---------------------------\n",
      "\n",
      "[[ 8  0  0]\n",
      " [ 0 12  0]\n",
      " [ 0  0 10]]\n",
      "\n",
      "----------------------------Tree with depth: 5 -----------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      0.92      0.96        12\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "----------------------------Confusion Matrix---------------------------\n",
      "\n",
      "[[ 8  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0 10]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahmoud/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    predicted = DecisionTreeClassifier(max_depth = (i+1), min_samples_leaf = 2, min_samples_split = 5).fit(data_train, target_train).predict(data_test)\n",
    "    print(\"----------------------------Tree with depth: \" + str(i+1)+\" -----------------------\\n\")\n",
    "    print(metrics.classification_report(target_test,\n",
    "                                    predicted))\n",
    "    print(\"----------------------------Confusion Matrix---------------------------\\n\")\n",
    "    print(metrics.confusion_matrix(target_test,\n",
    "                               predicted))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "***\n",
    "Load the **Breast Cancer Wisconsin (Diagnostic)** sample dataset from the **UCI Machine Learning Repository** (The discrete version at: **breast-cancer-wisconsin.data**)  into Python using  a  Pandas  dataframe.   Induce  a  binary Decision Tree with a minimum of 2 instances in the leaves, no splits of subsets below 5, and a maximal tree depth of 2 (use the default Gini criterion). Calculate the  Entropy,  Gini,  and  Misclassification  Error  of  the  first  split  -  what  is  the Information  Gain?   What  is  the  feature  selected  for  the  first  split,  and  what value determines the decision boundary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Entropy of the first split left child: 0.18411742692826688 <br/> \n",
    "Entropy of the first split right child: 0.6144552279266028 <br/>\n",
    "Total Entropy first split: 0.7985726548548697 </br>\n",
    "Gini of the first split left child: 0.05437918724632018 <br/> \n",
    "Gini of the first split right child:0.2575857338820302 <br/>\n",
    "Total Gini first split: 0.3119649211283504 <br/>\n",
    "Misclassification of the first split left child: 0.027972027972028024 <br/> \n",
    "Misclassification of the first split right child: 0.1518518518518519 <br/>\n",
    "Total Misclassification first split: 0.17982387982387993 <br/>\n",
    "The information gain of first split: 0.5789756086483544 <br/>\n",
    "\n",
    "The feature for the first split is Uniformity of Cell Size. The decision boundary in this feature is 2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump Thickness                0\n",
       "Uniformity of Cell Size        0\n",
       "Uniformity of Cell Shape       0\n",
       "Marginal Adhesion              0\n",
       "Single Epithelial Cell Size    0\n",
       "Bare Nuclei                    0\n",
       "Bland Chromatin                0\n",
       "Normal Nucleoli                0\n",
       "Mitoses                        0\n",
       "Class:                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\", header=None)\n",
    "breast.columns=[\"Sample code number\",\"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\", \n",
    "                \"Marginal Adhesion\", \"Single Epithelial Cell Size\",\"Bare Nuclei\", \"Bland Chromatin\", \n",
    "                \"Normal Nucleoli\", \"Mitoses\", \"Class:\"]\n",
    "breast_pd = breast.drop(columns=[\"Sample code number\"])\n",
    "imp_breast_pd = breast_pd.replace(to_replace=\"?\",value=0)\n",
    "imp_breast_pd.isna().sum() #All the nan values are in Bare Nuclei column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "count       699.000000               699.000000                699.000000   \n",
       "mean          4.417740                 3.134478                  3.207439   \n",
       "std           2.815741                 3.051459                  2.971913   \n",
       "min           1.000000                 1.000000                  1.000000   \n",
       "25%           2.000000                 1.000000                  1.000000   \n",
       "50%           4.000000                 1.000000                  1.000000   \n",
       "75%           6.000000                 5.000000                  5.000000   \n",
       "max          10.000000                10.000000                 10.000000   \n",
       "\n",
       "       Marginal Adhesion  Single Epithelial Cell Size  Bland Chromatin  \\\n",
       "count         699.000000                   699.000000       699.000000   \n",
       "mean            2.806867                     3.216023         3.437768   \n",
       "std             2.855379                     2.214300         2.438364   \n",
       "min             1.000000                     1.000000         1.000000   \n",
       "25%             1.000000                     2.000000         2.000000   \n",
       "50%             1.000000                     2.000000         3.000000   \n",
       "75%             4.000000                     4.000000         5.000000   \n",
       "max            10.000000                    10.000000        10.000000   \n",
       "\n",
       "       Normal Nucleoli     Mitoses      Class:  \n",
       "count       699.000000  699.000000  699.000000  \n",
       "mean          2.866953    1.589413    2.689557  \n",
       "std           3.053634    1.715078    0.951273  \n",
       "min           1.000000    1.000000    2.000000  \n",
       "25%           1.000000    1.000000    2.000000  \n",
       "50%           1.000000    1.000000    2.000000  \n",
       "75%           4.000000    1.000000    4.000000  \n",
       "max          10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_breast_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Uniformity of Cell Size', 'Bland Chromatin', 'Mitoses', 'Mitoses',\n",
       "       'Uniformity of Cell Shape', 'Mitoses', 'Mitoses'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_tree = DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 2, min_samples_split = 5)\n",
    "fitted_breast = breast_tree.fit(imp_breast_pd.drop(columns=[\"Class:\",\"Bare Nuclei\"]), imp_breast_pd[\"Class:\"])\n",
    "imp_breast_pd.columns[fitted_breast.tree_.feature] #Order of splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.88020446, 0.07898489, 0.        , 0.        ,\n",
       "       0.        , 0.04081065, 0.        ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_breast.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      "Clump Thickness                699 non-null int64\n",
      "Uniformity of Cell Size        699 non-null int64\n",
      "Uniformity of Cell Shape       699 non-null int64\n",
      "Marginal Adhesion              699 non-null int64\n",
      "Single Epithelial Cell Size    699 non-null int64\n",
      "Bare Nuclei                    699 non-null float64\n",
      "Bland Chromatin                699 non-null int64\n",
      "Normal Nucleoli                699 non-null int64\n",
      "Mitoses                        699 non-null int64\n",
      "Class:                         699 non-null int64\n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 54.7 KB\n"
     ]
    }
   ],
   "source": [
    "imp_breast_pd[\"Bare Nuclei\"] = imp_breast_pd[\"Bare Nuclei\"].astype(np.float64)\n",
    "imp_breast_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump Thickness                0\n",
       "Uniformity of Cell Size        0\n",
       "Uniformity of Cell Shape       0\n",
       "Marginal Adhesion              0\n",
       "Single Epithelial Cell Size    0\n",
       "Bare Nuclei                    0\n",
       "Bland Chromatin                0\n",
       "Normal Nucleoli                0\n",
       "Mitoses                        0\n",
       "Class:                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_breast_pd.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Uniformity of Cell Size', 'Bare Nuclei', 'Mitoses', 'Mitoses',\n",
       "       'Uniformity of Cell Shape', 'Mitoses', 'Mitoses'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fitted_breast = breast_tree.fit(imp_breast_pd.drop(columns=[\"Class:\"]), imp_breast_pd[\"Class:\"])\n",
    "imp_breast_pd.columns[new_fitted_breast.tree_.feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.87550059, 0.07856279, 0.        , 0.        ,\n",
       "       0.04593662, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fitted_breast.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.5,  5.5, -2. , -2. ,  2.5, -2. , -2. ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fitted_breast.tree_.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.463519</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>3.640708</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "count       699.000000               699.000000                699.000000   \n",
       "mean          4.417740                 3.134478                  3.207439   \n",
       "std           2.815741                 3.051459                  2.971913   \n",
       "min           1.000000                 1.000000                  1.000000   \n",
       "25%           2.000000                 1.000000                  1.000000   \n",
       "50%           4.000000                 1.000000                  1.000000   \n",
       "75%           6.000000                 5.000000                  5.000000   \n",
       "max          10.000000                10.000000                 10.000000   \n",
       "\n",
       "       Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "count         699.000000                   699.000000   699.000000   \n",
       "mean            2.806867                     3.216023     3.463519   \n",
       "std             2.855379                     2.214300     3.640708   \n",
       "min             1.000000                     1.000000     0.000000   \n",
       "25%             1.000000                     2.000000     1.000000   \n",
       "50%             1.000000                     2.000000     1.000000   \n",
       "75%             4.000000                     4.000000     5.000000   \n",
       "max            10.000000                    10.000000    10.000000   \n",
       "\n",
       "       Bland Chromatin  Normal Nucleoli     Mitoses      Class:  \n",
       "count       699.000000       699.000000  699.000000  699.000000  \n",
       "mean          3.437768         2.866953    1.589413    2.689557  \n",
       "std           2.438364         3.053634    1.715078    0.951273  \n",
       "min           1.000000         1.000000    1.000000    2.000000  \n",
       "25%           2.000000         1.000000    1.000000    2.000000  \n",
       "50%           3.000000         1.000000    1.000000    2.000000  \n",
       "75%           5.000000         4.000000    1.000000    4.000000  \n",
       "max          10.000000        10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_breast_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Node Entropy:  0.9293179372497982\n",
      "First Node Gini:  0.4518124195406886\n",
      "First Node missclassification:  0.3447782546494993\n"
     ]
    }
   ],
   "source": [
    "print(\"First Node Entropy: \", my_entropy(imp_breast_pd, \"Class:\"))\n",
    "print(\"First Node Gini: \",my_gini(imp_breast_pd, \"Class:\"))\n",
    "print(\"First Node missclassification: \", my_misclass(imp_breast_pd, \"Class:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2575857338820302"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_right = new_fitted_breast.tree_.children_right[0] #4\n",
    "new_fitted_breast.tree_.impurity[index_right]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05437918724632007"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_left = new_fitted_breast.tree_.children_left[0] # 1\n",
    "new_fitted_breast.tree_.impurity[index_left]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "Uniformity of Cell Size\n"
     ]
    }
   ],
   "source": [
    "tresh = new_fitted_breast.tree_.threshold[0]\n",
    "print(tresh)\n",
    "f1 = imp_breast_pd.columns[new_fitted_breast.tree_.feature[0]]\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightchild = imp_breast_pd[imp_breast_pd[f1] > tresh]\n",
    "leftchild = imp_breast_pd[imp_breast_pd[f1] <= tresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.766667</td>\n",
       "      <td>6.359259</td>\n",
       "      <td>6.214815</td>\n",
       "      <td>5.211111</td>\n",
       "      <td>5.074074</td>\n",
       "      <td>6.840741</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>5.514815</td>\n",
       "      <td>2.418519</td>\n",
       "      <td>3.696296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.576921</td>\n",
       "      <td>2.646560</td>\n",
       "      <td>2.708613</td>\n",
       "      <td>3.246369</td>\n",
       "      <td>2.468025</td>\n",
       "      <td>3.606145</td>\n",
       "      <td>2.442499</td>\n",
       "      <td>3.404262</td>\n",
       "      <td>2.462890</td>\n",
       "      <td>0.719087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "count       270.000000               270.000000                270.000000   \n",
       "mean          6.766667                 6.359259                  6.214815   \n",
       "std           2.576921                 2.646560                  2.708613   \n",
       "min           1.000000                 3.000000                  1.000000   \n",
       "25%           5.000000                 4.000000                  4.000000   \n",
       "50%           7.000000                 6.000000                  6.000000   \n",
       "75%           9.000000                 9.000000                  8.000000   \n",
       "max          10.000000                10.000000                 10.000000   \n",
       "\n",
       "       Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "count         270.000000                   270.000000   270.000000   \n",
       "mean            5.211111                     5.074074     6.840741   \n",
       "std             3.246369                     2.468025     3.606145   \n",
       "min             1.000000                     2.000000     0.000000   \n",
       "25%             2.000000                     3.000000     3.000000   \n",
       "50%             5.000000                     5.000000     9.000000   \n",
       "75%             8.000000                     6.000000    10.000000   \n",
       "max            10.000000                    10.000000    10.000000   \n",
       "\n",
       "       Bland Chromatin  Normal Nucleoli     Mitoses      Class:  \n",
       "count       270.000000       270.000000  270.000000  270.000000  \n",
       "mean          5.600000         5.514815    2.418519    3.696296  \n",
       "std           2.442499         3.404262    2.462890    0.719087  \n",
       "min           1.000000         1.000000    1.000000    2.000000  \n",
       "25%           3.000000         3.000000    1.000000    4.000000  \n",
       "50%           6.000000         5.000000    1.000000    4.000000  \n",
       "75%           7.000000         9.000000    3.000000    4.000000  \n",
       "max          10.000000        10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rightchild.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.939394</td>\n",
       "      <td>1.104895</td>\n",
       "      <td>1.314685</td>\n",
       "      <td>1.293706</td>\n",
       "      <td>2.046620</td>\n",
       "      <td>1.337995</td>\n",
       "      <td>2.076923</td>\n",
       "      <td>1.200466</td>\n",
       "      <td>1.067599</td>\n",
       "      <td>2.055944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.756446</td>\n",
       "      <td>0.306776</td>\n",
       "      <td>0.704653</td>\n",
       "      <td>0.855156</td>\n",
       "      <td>0.786967</td>\n",
       "      <td>1.311337</td>\n",
       "      <td>1.068300</td>\n",
       "      <td>0.846598</td>\n",
       "      <td>0.527380</td>\n",
       "      <td>0.330170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "count       429.000000               429.000000                429.000000   \n",
       "mean          2.939394                 1.104895                  1.314685   \n",
       "std           1.756446                 0.306776                  0.704653   \n",
       "min           1.000000                 1.000000                  1.000000   \n",
       "25%           1.000000                 1.000000                  1.000000   \n",
       "50%           3.000000                 1.000000                  1.000000   \n",
       "75%           4.000000                 1.000000                  1.000000   \n",
       "max          10.000000                 2.000000                  4.000000   \n",
       "\n",
       "       Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "count         429.000000                   429.000000   429.000000   \n",
       "mean            1.293706                     2.046620     1.337995   \n",
       "std             0.855156                     0.786967     1.311337   \n",
       "min             1.000000                     1.000000     0.000000   \n",
       "25%             1.000000                     2.000000     1.000000   \n",
       "50%             1.000000                     2.000000     1.000000   \n",
       "75%             1.000000                     2.000000     1.000000   \n",
       "max            10.000000                    10.000000    10.000000   \n",
       "\n",
       "       Bland Chromatin  Normal Nucleoli     Mitoses      Class:  \n",
       "count       429.000000       429.000000  429.000000  429.000000  \n",
       "mean          2.076923         1.200466    1.067599    2.055944  \n",
       "std           1.068300         0.846598    0.527380    0.330170  \n",
       "min           1.000000         1.000000    1.000000    2.000000  \n",
       "25%           1.000000         1.000000    1.000000    2.000000  \n",
       "50%           2.000000         1.000000    1.000000    2.000000  \n",
       "75%           3.000000         1.000000    1.000000    2.000000  \n",
       "max           7.000000        10.000000    8.000000    4.000000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftchild.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left child entropy:  0.18411742692826688\n",
      "Left child gini:  0.05437918724632018\n",
      "Left child missclassification:  0.027972027972028024\n"
     ]
    }
   ],
   "source": [
    "print(\"Left child entropy: \", my_entropy(leftchild, \"Class:\"))\n",
    "print(\"Left child gini: \", my_gini(leftchild, \"Class:\"))\n",
    "print(\"Left child missclassification: \",my_misclass(leftchild, \"Class:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Child entropy:  0.6144552279266028\n",
      "Right Child gini:  0.2575857338820302\n",
      "Right Child missclassification:  0.1518518518518519\n"
     ]
    }
   ],
   "source": [
    "print(\"Right Child entropy: \", my_entropy(rightchild, \"Class:\"))\n",
    "print(\"Right Child gini: \", my_gini(rightchild, \"Class:\"))\n",
    "print(\"Right Child missclassification: \", my_misclass(rightchild, \"Class:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infomation Gain from Uniformity of Cell Size:  0.5789756086483544\n"
     ]
    }
   ],
   "source": [
    "print(\"Infomation Gain from Uniformity of Cell Size: \", information_gain(imp_breast_pd, leftchild, rightchild, \"Class:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_train_data, breast_test_data,breast_train_class, breast_test_class = model_selection.train_test_split(imp_breast_pd.drop(columns=\"Class:\"),\n",
    "                                                                    imp_breast_pd[\"Class:\"],\n",
    "                                                                    test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.94      0.96      0.95       100\n",
      "           4       0.89      0.85      0.87        40\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       140\n",
      "   macro avg       0.92      0.91      0.91       140\n",
      "weighted avg       0.93      0.93      0.93       140\n",
      "\n",
      "[[96  4]\n",
      " [ 6 34]]\n"
     ]
    }
   ],
   "source": [
    "breast_tree = DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 2, min_samples_split = 5).fit(breast_train_data, breast_train_class)\n",
    "\n",
    "#print(\"----------------------------Tree with depth classification-----------------------\\n\")\n",
    "print(metrics.classification_report(breast_test_class, breast_tree.predict(breast_test_data)))\n",
    "#print(\"----------------------------Confusion Matrix---------------------------\\n\")\n",
    "print(metrics.confusion_matrix(breast_test_class,breast_tree.predict(breast_test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "Load the **Breast Cancer Wisconsin (Diagnostic)** sample dataset from the **UCI Machine  Learning  Repository**  (The continuous version  at: **wdbc.data**)  into Python using  a  Pandas  dataframe.   Induce  the  same  binary  Decision  Tree as above (now using the continuous data) but perform a PCA dimensionality reduction beforehand.  Using only the first principal component of the data for a model fit, what is the F1, Precision, and Recall of the PCA-based single factor model compared to the original (continuous) data?  Repeat using the first and second principal components.  Using the Confusion Matrix, what are the values for  FP  and  TP  as  well  as  FPR/TPR?  Is  using  continuous  data  in  this  case beneficial within the model?  How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "The F1 score of PC1: micro avg: 0.94, macro avg: 0.93, and weighted avg: 0.94 <br/>\n",
    "The precision of PC1: micro avg: 0.94, macro avg: 0.96, and weighted avg: 0.94 <br/>\n",
    "The recall of PC1: micro avg: 0.94, macro avg: 0.91, and weighted avg: 0.94 <br/>\n",
    "\n",
    "The precision of original: micro avg:  0.93 macro avg:  0.93 weighted avg:  0.93<br/>\n",
    "The recall of original: micro avg:  0.93 macro avg:  0.92 weighted avg:  0.93<br/>\n",
    "The F1 score of original: micro avg:  0.93 macro avg:  0.92 weighted avg:  0.93<br/>\n",
    "\n",
    "The PC1 classifier improved on the classifier trained on the original dataset. This improvement was small only contributing 1%-2%.\n",
    "\n",
    "The FP for B is 0 and the TP for B is 77.\n",
    "The FP for M is 7 and the TP for M is 30.\n",
    "\n",
    "The TPR for B is 0.9166 and the FPR for B is 0.\n",
    "The TPR for M is 1 and the FPR is 0.083333.\n",
    "\n",
    "Using continous data is beneficial because it improves F1 score, precision and recall. Also it also us to easily reduce the size of our data while still capturing the features that we want.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_breast_pd = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\", header=None)\n",
    "#cont_breast_pd.columns = [\"ID\", \"Diagnosis\",radius\",\"texture\", \"perimeter\", \"area\", \"smoothness\",\"compactness\",\n",
    " #                         \"concavity\",\"concave points\",\"symmetry\",\"fractal dimension\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      "0     569 non-null int64\n",
      "1     569 non-null object\n",
      "2     569 non-null float64\n",
      "3     569 non-null float64\n",
      "4     569 non-null float64\n",
      "5     569 non-null float64\n",
      "6     569 non-null float64\n",
      "7     569 non-null float64\n",
      "8     569 non-null float64\n",
      "9     569 non-null float64\n",
      "10    569 non-null float64\n",
      "11    569 non-null float64\n",
      "12    569 non-null float64\n",
      "13    569 non-null float64\n",
      "14    569 non-null float64\n",
      "15    569 non-null float64\n",
      "16    569 non-null float64\n",
      "17    569 non-null float64\n",
      "18    569 non-null float64\n",
      "19    569 non-null float64\n",
      "20    569 non-null float64\n",
      "21    569 non-null float64\n",
      "22    569 non-null float64\n",
      "23    569 non-null float64\n",
      "24    569 non-null float64\n",
      "25    569 non-null float64\n",
      "26    569 non-null float64\n",
      "27    569 non-null float64\n",
      "28    569 non-null float64\n",
      "29    569 non-null float64\n",
      "30    569 non-null float64\n",
      "31    569 non-null float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cont_breast_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               2           3           4            5           6   \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    14.127292   19.289649   91.969033   654.889104    0.096360   \n",
       "std      3.524049    4.301036   24.298981   351.914129    0.014064   \n",
       "min      6.981000    9.710000   43.790000   143.500000    0.052630   \n",
       "25%     11.700000   16.170000   75.170000   420.300000    0.086370   \n",
       "50%     13.370000   18.840000   86.240000   551.100000    0.095870   \n",
       "75%     15.780000   21.800000  104.100000   782.700000    0.105300   \n",
       "max     28.110000   39.280000  188.500000  2501.000000    0.163400   \n",
       "\n",
       "               7           8           9           10          11     ...      \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000     ...       \n",
       "mean     0.104341    0.088799    0.048919    0.181162    0.062798     ...       \n",
       "std      0.052813    0.079720    0.038803    0.027414    0.007060     ...       \n",
       "min      0.019380    0.000000    0.000000    0.106000    0.049960     ...       \n",
       "25%      0.064920    0.029560    0.020310    0.161900    0.057700     ...       \n",
       "50%      0.092630    0.061540    0.033500    0.179200    0.061540     ...       \n",
       "75%      0.130400    0.130700    0.074000    0.195700    0.066120     ...       \n",
       "max      0.345400    0.426800    0.201200    0.304000    0.097440     ...       \n",
       "\n",
       "               22          23          24           25          26  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
       "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
       "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
       "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
       "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
       "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
       "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
       "\n",
       "               27          28          29          30          31  \n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
       "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
       "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
       "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
       "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
       "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
       "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
       "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cont_breast_pd = cont_breast_pd.drop(columns=[0,1])\n",
    "data_cont_breast_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.2045 0.982045\n",
      "1.6176 0.016176\n",
      "0.1558 0.001558\n",
      "0.0121 0.000121\n",
      "0.0088 8.8e-05\n",
      "0.0007 7e-06\n",
      "0.00039999999999999996 4e-06\n",
      "9.999999999999999e-05 1e-06\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pca_breast = PCA()\n",
    "fitted_pca = pca_breast.fit(data_cont_breast_pd)\n",
    "pca_breast_percent_var = np.around(pca_breast.explained_variance_ratio_, 6)\n",
    "for i in range(len(pca_breast_percent_var)):\n",
    "    print(pca_breast_percent_var[i]*100, pca_breast_percent_var[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98204467])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_pca_breast = PCA(n_components =1)\n",
    "first_pca_comp = first_pca_breast.fit_transform(data_cont_breast_pd)\n",
    "first_pca_breast.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.196817932418026e-14"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_pca_comp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.89      0.98      0.93        64\n",
      "           M       0.98      0.84      0.90        50\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "[[63  1]\n",
      " [ 8 42]]\n"
     ]
    }
   ],
   "source": [
    "breast_x, breast_x_test, breast_y, breast_y_test = model_selection.train_test_split(first_pca_comp,\n",
    "                                                                    cont_breast_pd[1],\n",
    "                                                                    test_size=0.2)\n",
    "dt_breast = DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 2,min_samples_split = 5).fit(breast_x, breast_y)\n",
    "\n",
    "\n",
    "#print(\"----------------------------Tree with depth classification-----------------------\\n\")\n",
    "print(metrics.classification_report(breast_y_test, dt_breast.predict(breast_x_test)))\n",
    "#print(\"----------------------------Confusion Matrix---------------------------\\n\")\n",
    "print(metrics.confusion_matrix(breast_y_test,dt_breast.predict(breast_x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.85      0.90        80\n",
      "           M       0.72      0.91      0.81        34\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       114\n",
      "   macro avg       0.84      0.88      0.85       114\n",
      "weighted avg       0.89      0.87      0.87       114\n",
      "\n",
      "[[68 12]\n",
      " [ 3 31]]\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_target, test_target = model_selection.train_test_split(data_cont_breast_pd,\n",
    "                                                                    cont_breast_pd[1],\n",
    "                                                                    test_size=0.2)\n",
    "dt_cont_breast = DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 2,min_samples_split = 5).fit(train_data, train_target)\n",
    "\n",
    "\n",
    "#print(\"----------------------------Tree with depth classification-----------------------\\n\")\n",
    "print(metrics.classification_report(test_target, dt_cont_breast.predict(test_data)))\n",
    "#print(\"----------------------------Confusion Matrix---------------------------\\n\")\n",
    "print(metrics.confusion_matrix(test_target,dt_cont_breast.predict(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98204467, 0.01617649])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_pca_breast = PCA(n_components =2)\n",
    "two_pca_comp = two_pca_breast.fit_transform(data_cont_breast_pd)\n",
    "two_pca_breast.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1160.1425737 , -293.91754364],\n",
       "       [1269.12244319,   15.63018184],\n",
       "       [ 995.79388896,   39.15674324],\n",
       "       ...,\n",
       "       [ 314.50175618,   47.55352518],\n",
       "       [1124.85811531,   34.12922497],\n",
       "       [-771.52762188,  -88.64310636]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_pca_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.93      0.96      0.94        77\n",
      "           M       0.91      0.84      0.87        37\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "[[74  3]\n",
      " [ 6 31]]\n"
     ]
    }
   ],
   "source": [
    "train2_data, test2_data, train2_target, test2_target = model_selection.train_test_split(two_pca_comp,\n",
    "                                                                    cont_breast_pd[1],\n",
    "                                                                    test_size=0.2)\n",
    "dt_cont_breast = DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 2,\n",
    "                                        min_samples_split = 5).fit(train2_data, train2_target)\n",
    "\n",
    "\n",
    "#print(\"----------------------------Tree with depth classification-----------------------\\n\")\n",
    "print(metrics.classification_report(test2_target, dt_cont_breast.predict(test2_data)))\n",
    "#print(\"----------------------------Confusion Matrix---------------------------\\n\")\n",
    "print(metrics.confusion_matrix(test2_target,dt_cont_breast.predict(test2_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "Simulate a binary classification dataset with a single feature using a mixture of normal distributions with NumPy(Hint:  Generate two data frames with the random  number  and  a  class  label,  and  combine  them  together).   The  normal distribution  parameters  **np.random.normal**  should  be  (5,2)  and  (-5,2)  for the pair of samples.  Induce a binary Decision Tree of maximum depth 2, and obtain the threshold value for the feature in the first split.  How does this value compare to the empirical distribution of the feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "The split threshold of the first split is -0.48002306 which is very close to the median of concatinated random datasets. The median is actually at -0.06113229204151116. This would make sense as a split because most of c1 will be above this threshold and most of c2 will be less than the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.002313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.293827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-10.353750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.923400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.061132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.857598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.926335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                f1\n",
       "count  1000.000000\n",
       "mean     -0.002313\n",
       "std       5.293827\n",
       "min     -10.353750\n",
       "25%      -4.923400\n",
       "50%      -0.061132\n",
       "75%       4.857598\n",
       "max       9.926335"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(267) #267\n",
    "rand_data_1 = np.random.normal(5,2,500 )\n",
    "rand_data_2 = np.random.normal(-5, 2, 1000-500)\n",
    "class_1 = np.repeat(\"c1\", 500)\n",
    "class_2 = np.repeat(\"c2\", 1000-500)\n",
    "pd_1 = pd.DataFrame(dict(zip(['f1','Class'],[rand_data_1,class_1])))\n",
    "pd_2 = pd.DataFrame(dict(zip(['f1','Class'],[rand_data_2,class_2])))\n",
    "rand_data_frame = pd.concat([pd_1,pd_2])\n",
    "rand_data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.024599768152704"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_data_frame[\"f1\"].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48002306, -0.90108308, -2.        , -2.        ,  0.72923988,\n",
       "       -2.        , -2.        ])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_rand = DecisionTreeClassifier(max_depth = 2).fit(rand_data_frame.drop(columns=[\"Class\"]), rand_data_frame[\"Class\"])\n",
    "dt_rand.tree_.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f1', 'f1', 'f1', 'f1', 'f1', 'f1', 'f1'], dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_data_frame.columns[dt_rand.tree_.feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 499\n",
      "Data columns (total 2 columns):\n",
      "f1       1000 non-null float64\n",
      "Class    1000 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 23.4+ KB\n"
     ]
    }
   ],
   "source": [
    "rand_data_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min of c1:  -0.8461028881213419\n",
      "median of c1:  4.862024474793273\n",
      "Lower half of c1 median: 3.5262385889406183\n"
     ]
    }
   ],
   "source": [
    "print(\"min of c1: \", rand_data_frame[rand_data_frame[\"Class\"] == \"c1\"][\"f1\"].min())\n",
    "print(\"median of c1: \", rand_data_frame[rand_data_frame[\"Class\"] == \"c1\"][\"f1\"].median())\n",
    "c1_pd = rand_data_frame[rand_data_frame[\"Class\"] == \"c1\"]\n",
    "c1_pd = c1_pd[c1_pd[\"f1\"] < 4.86202]\n",
    "print(\"Lower half of c1 median:\", c1_pd[\"f1\"].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of c2:  0.7283188149442736\n",
      "median of c2:  -4.927450383347026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.655450304469958"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"max of c2: \", rand_data_frame[rand_data_frame[\"Class\"] == \"c2\"][\"f1\"].max())\n",
    "print(\"median of c2: \", rand_data_frame[rand_data_frame[\"Class\"] == \"c2\"][\"f1\"].median())\n",
    "c2_pd = rand_data_frame[rand_data_frame[\"Class\"] == \"c2\"] \n",
    "c2_pd = c2_pd[c2_pd[\"f1\"]> -4.92745]\n",
    "c2_pd[\"f1\"].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1   -0.061132\n",
       "dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pd_c1_c2 = pd.concat([c1_pd,c2_pd])\n",
    "sm_pd_c1_c2.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06113229204151116"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_data_frame[\"f1\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.002313271404979895"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_data_frame[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
