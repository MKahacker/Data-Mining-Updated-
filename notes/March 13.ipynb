{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adminstrativa \n",
    "\n",
    "Quiz comes out the weekend of March 15. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud computing is just a bunch of computers that do parts of a computation together.\n",
    "\n",
    "HDFS is a Hadoop Distributed File System. It is a file system that resides on multiple machines.\n",
    "\n",
    "MapReduce makes sure that the computation is done close to the data. Map makes the computation in the systems. Reduce gathers the results and makes sense of them. \n",
    "\n",
    "Spark is a newer dialect of MapReduce that does computation in memory. Has a better interface gives the developer a way to do data analysis like you would on R or Python\n",
    "\n",
    "Drill is Google's query but an open source version. \n",
    "\n",
    "Not on exam but good to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH (Local Senstivity Hashing)\n",
    "\n",
    "**Documents** \"Matrix/DF\"\n",
    "**Similarity** \"Neighbors\"\n",
    "\n",
    "Documents that are unstructured, are unexplored and can still be mined for interesting information.\n",
    "\n",
    "Almost all knowledge is stored in a document-format. \n",
    "\n",
    "Why do we look at similarity :-\n",
    "- Duplication\n",
    "- Source Construction\n",
    "- Plagarism/Fraud \n",
    "- Search/Information Retrieval\n",
    " - Recommender Systems\n",
    " - Document DataBases (NoSQL)\n",
    " - Web Search\n",
    "\n",
    "If you are a web source engine. You end up with duplicates. A lot of documents are just duplicates that have very small changes.\n",
    "\n",
    "**Methodology** :-\n",
    "- Documents should be treated as sets\n",
    " - Documents -> \"sets\" -> Intersection/Union\n",
    " - Out of the sets we look at intersection and union\n",
    " \n",
    "Example :- \n",
    "\"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "Ling/Math Crowd :- (semantic centric) \n",
    "- n-grams \n",
    "- n -words\n",
    "- Look at grammer and words after each other\n",
    " - Looks at documents as sequences of grams.\n",
    "\n",
    "CS :- (syntax centric)\n",
    "- k-char\n",
    "- k-shingles (\"ab\" or \"tes\") combination of characters.\n",
    "- Looks for sequence of characters\n",
    " - Looks at documents as sets of character sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have $D_1$ and $D_2$\n",
    "\n",
    "Than we can compute the Jaccard Similarity with $\\frac{D_1 \\cap D_2}{D_1 \\cup D_2} = \\frac{f_{11}}{f_{11}f_{10}f_{01}}$ where $D_1$ and $D_2$ have assymetric binary features. We only care about presence or absence. \n",
    "\n",
    "We can take the counts of a documents terms using a **bag** representation.\n",
    "\n",
    "bags use the counts and compute unions and interestions using actual counts.\n",
    "\n",
    "As you increase **k** in **k-shingles** than the similiraty drops because you can create a sparse dimension. If you increase **k** you get more documents that are closer to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH\n",
    "\n",
    "sizes of document matrices can become huge.\n",
    "\n",
    "Thus we need to **summarize** M (a sparse matrix because most documents don't have a majority of words) \n",
    "\n",
    "We have to \"preserve\" the Jaccard Similarity.\n",
    "\n",
    "The \"Signature Matrix\" is a compressed version of M.\n",
    "\n",
    "*Sim_in_M*($D_1$, $D_2$) agrees with *Sim_in_sig_matrix*($D_1$, $D_2$)\n",
    "\n",
    "This means that if *Sim_in_M*($D_1$, $D_2$) = a and *Sim_in_M*($D_3$, $D_4$) = b\n",
    "\n",
    "Than *Sim_in_sig_matrix*($D_1$, $D_2$) = x and *Sim_in_sig_matrix*($D_3$, $D_4$) = y\n",
    "\n",
    "(b-a) = + or - or 0 and (y-x) = + or - or 0 than they both have to be positive or negative or zero. This means that transformation is linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any pair of $D_i$, $D_j$ there are three situations in the rows :-\n",
    "\n",
    "$X$ both contain\n",
    "\n",
    "$Y$ one contains other doesn't\n",
    "\n",
    "$Z$ neither contains both don't contain. \n",
    "\n",
    "The probability of both documents having a k-shingle is $$\\frac{X}{X + Y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Matrix is N x S where S is the number of documents\n",
    "\n",
    "Signature Matrix is n x S where n < N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinHashing\n",
    "\n",
    "**MinHashing** :- \n",
    "- Start with original matrix M (N x S)\n",
    " - select n \"random\" hash functions.($h_1 .. h_n$)\n",
    " - set Signature Matrix sig(i, k) = $\\infty$\n",
    "- For each row r compute $h_1(r) .. h_n(r)$\n",
    "- For each column c \n",
    " - if c == 0\n",
    "  - than leave alone\n",
    " - else if c == 1\n",
    "  - than for each i in sig(i, c) set to min(sig(i,c), $h_i$(r))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a **minhash** run\n",
    "\n",
    "|Row| $s_1$ | $s_2$ | $s_3$ | $s_4$ | \n",
    "|---|-------|-------|-------|-------|\n",
    "|0  |1      |0|0|1|\n",
    "|1  |0|0|1|0|\n",
    "|2  |0|1|0|1|\n",
    "|3  |1|0|1|1|\n",
    "|4  |0|0|1|0|\n",
    "\n",
    "$h_1(x) = (x+1) mod 5$ \n",
    "\n",
    "$h_2(x) = (3x+1) mod 5$\n",
    "\n",
    "We computer $h_i$ for each row\n",
    "\n",
    "apply $h_1(x)$ r0 = 1, r1 = 2, r2 = 3, r3 = 4, r4 = 0\n",
    "\n",
    "$h_2(x)$ r0 = 1, r1 = 4, r2 = 2, r3 = 0, r4 = 3\n",
    "\n",
    "Signature Matrix :\n",
    "\n",
    "|Row| $s_1$ | $s_2$ | $s_3$ | $s_4$ | \n",
    "|---|-------|-------|-------|-------|\n",
    "|$h_1$  |1      |3|0|1|\n",
    "|$h_2$  |0      |2|0|0|\n",
    "\n",
    "-----------------------------------------------NOT DONE look at slides to complete -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aproximate NN**\n",
    "- IM docs: IM choose 2 approximiate 500Billion pairs\n",
    "- Minmium Threshold of similarity\n",
    "\n",
    "Create multiple hashes that create buckets of similar documents.\n",
    "\n",
    "If a subset is similar than we want to hash them to the same bucket. \n",
    "\n",
    "We determine similarity by looking at the first couple terms and compare them.\n",
    "\n",
    "So we divide Sig Matrix into *b* banks of r rows. For each band $b_i$ take a hash of the r rows to some large set. What we should see is that all the similar ones end up in the same bucket.\n",
    "\n",
    "If documents are found in many bands than they meet a similarity threshold. \n",
    "\n",
    "s documents that meet a certain jacard similarity.\n",
    "\n",
    "If they are only similar in a one band than we know that they aren't the same.\n",
    "\n",
    "prob all rows in a band match: $$s^r$$\n",
    "\n",
    "prob not: $$1 - s^r$$ \n",
    "\n",
    "prob they disgree at aleast 1 row in each band: $$(1-s^r)^b$$\n",
    "\n",
    "prob they agree at aleast 1 row in each band: $$ 1-(1-s^r)^b$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use $f(s) = 1 - (1 - s^r)^b$\n",
    "\n",
    "to tell which r and b to use along with how many hashes we have those are the rows of the signature matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaccard Simmilarity for sets\n",
    "$$sim(c_1, c_2) = \\frac{|c_1\\cap c_2|}{|c_1\\cup c_2|}$$\n",
    "\n",
    "Jaccard Distance for sets\n",
    "$$1 - sim(c_1, c_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Shingling involves converting a larger document to sets. For example dividing a document to k-shingles. where each shingle is a character and then comparing the documents based on the shingles. Shingles can also be sets of words based on the application. The point is that shingles perserve order better than just looking at frequency or words. A bag approach keeps track of duplicate shingles as compared to a set which has no duplicates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We can compress shingles by hashing them. We can represent the document with the set of hash based on the set of k-shingles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Example: d1 = {abcd}. 2-shingles(d1) = {ab, bc,cd}. h(d1) = {1, 5, 7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    When picking shingles you have to pick a big enough shingle or all the documents will be similar. A k=5 is pretty good for small documents and k =10 for bigger documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Min-Hashing: converts a large set to small signature. Short integer matrices that represent the original documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Converting to a boolean set the rows are shingles and the columns are documents. There is a one in the row and column if the document contains the shingle. In order to avoid comparing all the columns for similarity we can hash each column. This hash should be small enough to fit into RAM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Jaccard similarity \n",
    "$$sim(c_1, c_2)$$ then becomes the similarity between \n",
    "$$h(c_1) == h(c_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The goal is to find a hash function where if sim(c1,c2) is high than with high prob h(c1) == h(c2)\n",
    "    and if sim(c1, c2) is low than with high prob h(c1) != h(c2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Each h(.) represents the hash of a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    In order to achieve the goal of the hashing function we can use the function min-hashing. We first permute the items in random permutations using a hash function then we build a matrix based on where the first 1 occurs for every document. If the first 1 occurs in the same place for both documents they are similar otherwise they are different. If we do enough permutations we approximiate jaccard pretty accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The signature matrix will save the smallest column in the random permutation that has a one. We don't actually jumble up the actual rows we just jumble up the indices. Thus the sig matrix just has the minimum indices with a 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Local sensitive Hashing: looking at signatures to determine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Once you have the signature matrix we can estimate the jaccard matrix by looking at the signature matrix and seeing if the documents columns have similar index numbers. Thus computing the similarity.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Now we find the documents that have a jaccard similarity of a certain threshold. LSH aims to find a function f(x,y) which will tell you if x and y should be evaulated. We can do this by using a bucket where part of two documents are similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We can do this by dividing the Signature matrix M into b bands and r rows in each band. Than for each column in a band we hash to a hash table. With k buckets. Candidate pairs are the ones that have multiple similar buckets for more than 1 bucket. You want to tweak the number of bands and rows till you get a small number of nonsimilar candidate pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability that c1 and c2 are not similar in b=20 and r=5 if c1 and c2 are actually similar for probability p\n",
    "$$(1 - p^r)^b$$\n",
    "p is the threshold of similarity.\n",
    "Probability atleast 1 band is similar \n",
    "$$1 - (1 - p^r)^b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
