{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adminstrativa \n",
    "\n",
    "Quiz comes out the weekend of March 15. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud computing is just a bunch of computers that do parts of a computation together.\n",
    "\n",
    "HDFS is a Hadoop Distributed File System. It is a file system that resides on multiple machines.\n",
    "\n",
    "MapReduce makes sure that the computation is done close to the data. Map makes the computation in the systems. Reduce gathers the results and makes sense of them. \n",
    "\n",
    "Spark is a newer dialect of MapReduce that does computation in memory. Has a better interface gives the developer a way to do data analysis like you would on R or Python\n",
    "\n",
    "Drill is Google's query but an open source version. \n",
    "\n",
    "Not on exam but good to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH (Local Senstivity Hashing)\n",
    "\n",
    "**Documents** \"Matrix/DF\"\n",
    "**Similarity** \"Neighbors\"\n",
    "\n",
    "Documents that are unstructured, are unexplored and can still be mined for interesting information.\n",
    "\n",
    "Almost all knowledge is stored in a document-format. \n",
    "\n",
    "Why do we look at similarity :-\n",
    "- Duplication\n",
    "- Source Construction\n",
    "- Plagarism/Fraud \n",
    "- Search/Information Retrieval\n",
    " - Recommender Systems\n",
    " - Document DataBases (NoSQL)\n",
    " - Web Search\n",
    "\n",
    "If you are a web source engine. You end up with duplicates. A lot of documents are just duplicates that have very small changes.\n",
    "\n",
    "**Methodology** :-\n",
    "- Documents should be treated as sets\n",
    " - Documents -> \"sets\" -> Intersection/Union\n",
    " - Out of the sets we look at intersection and union\n",
    " \n",
    "Example :- \n",
    "\"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "Ling/Math Crowd :- (semantic centric) \n",
    "- n-grams \n",
    "- n -words\n",
    "- Look at grammer and words after each other\n",
    " - Looks at documents as sequences of grams.\n",
    "\n",
    "CS :- (syntax centric)\n",
    "- k-char\n",
    "- k-shingles (\"ab\" or \"tes\") combination of characters.\n",
    "- Looks for sequence of characters\n",
    " - Looks at documents as sets of character sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have $D_1$ and $D_2$\n",
    "\n",
    "Than we can compute the Jaccard Similarity with $\\frac{D_1 \\cap D_2}{D_1 \\cup D_2} = \\frac{f_{11}}{f_{11}f_{10}f_{01}}$ where $D_1$ and $D_2$ have assymetric binary features. We only care about presence or absence. \n",
    "\n",
    "We can take the counts of a documents terms using a **bag** representation.\n",
    "\n",
    "bags use the counts and compute unions and interestions using actual counts.\n",
    "\n",
    "As you increase **k** in **k-shingles** than the similiraty drops because you can create a sparse dimension. If you increase **k** you get more documents that are closer to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH\n",
    "\n",
    "sizes of document matrices can become huge.\n",
    "\n",
    "Thus we need to **summarize** M (a sparse matrix because most documents don't have a majority of words) \n",
    "\n",
    "We have to \"preserve\" the Jaccard Similarity.\n",
    "\n",
    "The \"Signature Matrix\" is a compressed version of M.\n",
    "\n",
    "*Sim_in_M*($D_1$, $D_2$) agrees with *Sim_in_sig_matrix*($D_1$, $D_2$)\n",
    "\n",
    "This means that if *Sim_in_M*($D_1$, $D_2$) = a and *Sim_in_M*($D_3$, $D_4$) = b\n",
    "\n",
    "Than *Sim_in_sig_matrix*($D_1$, $D_2$) = x and *Sim_in_sig_matrix*($D_3$, $D_4$) = y\n",
    "\n",
    "(b-a) = + or - or 0 and (y-x) = + or - or 0 than they both have to be positive or negative or zero. This means that transformation is linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any pair of $D_i$, $D_j$ there are three situations in the rows :-\n",
    "\n",
    "$X$ both contain\n",
    "\n",
    "$Y$ one contains other doesn't\n",
    "\n",
    "$Z$ neither contains both don't contain. \n",
    "\n",
    "The probability of both documents having a k-shingle is $$\\frac{X}{X + Y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Matrix is N x S where S is the number of documents\n",
    "\n",
    "Signature Matrix is n x S where n < N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinHashing\n",
    "\n",
    "**MinHashing** :- \n",
    "- Start with original matrix M (N x S)\n",
    " - select n \"random\" hash functions.($h_1 .. h_n$)\n",
    " - set Signature Matrix sig(i, k) = $\\infty$\n",
    "- For each row r compute $h_1(r) .. h_n(r)$\n",
    "- For each column c \n",
    " - if c == 0\n",
    "  - than leave alone\n",
    " - else if c == 1\n",
    "  - than for each i in sig(i, c) set to min(sig(i,c), $h_i$(r))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a **minhash** run\n",
    "\n",
    "|Row| $s_1$ | $s_2$ | $s_3$ | $s_4$ | \n",
    "|---|-------|-------|-------|-------|\n",
    "|0  |1      |0|0|1|\n",
    "|1  |0|0|1|0|\n",
    "|2  |0|1|0|1|\n",
    "|3  |1|0|1|1|\n",
    "|4  |0|0|1|0|\n",
    "\n",
    "$h_1(x) = (x+1) mod 5$ \n",
    "\n",
    "$h_2(x) = (3x+1) mod 5$\n",
    "\n",
    "We computer $h_i$ for each row\n",
    "\n",
    "apply $h_1(x)$ r0 = 1, r1 = 2, r2 = 3, r3 = 3, r\n",
    "\n",
    "Signature Matrix :\n",
    "\n",
    "|Row| $s_1$ | $s_2$ | $s_3$ | $s_4$ | \n",
    "|---|-------|-------|-------|-------|\n",
    "|$h_1$  |1      |3|0|1|\n",
    "|$h_2$  |0      |2|0|0|\n",
    "\n",
    "-----------------------------------------------NOT DONE look at slides to complete -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aproximate NN**\n",
    "- IM docs: IM choose 2 approximiate 500Billion pairs\n",
    "- Minmium Threshold of similarity\n",
    "\n",
    "Create multiple hashes that create buckets of similar documents.\n",
    "\n",
    "If a subset is similar than we want to hash them to the same bucket. \n",
    "\n",
    "We determine similarity by looking at the first couple terms and compare them.\n",
    "\n",
    "So we divide Sig Matrix into *b* banks of r rows. For each band $b_i$ take a hash of the r rows to some large set. What we should see is that all the similar ones end up in the same bucket.\n",
    "\n",
    "If documents are found in many bands than they meet a similarity threshold. \n",
    "\n",
    "s documents that meet a certain jacard similarity.\n",
    "\n",
    "If they are only similar in a one band than we know that they aren't the same.\n",
    "\n",
    "prob all rows in a band match: $$s^r$$\n",
    "\n",
    "prob not: $$1 - s^r$$ \n",
    "\n",
    "prob they disgree at aleast 1 row in each band: $$(1-s^r)^b$$\n",
    "\n",
    "prob they agree at aleast 1 row in each band: $$ 1-(1-s^r)^b$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use $f(s) = 1 - (1 - s^r)^b$\n",
    "\n",
    "to tell which r and b to use along with how many hashes we have those are the rows of the signature matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
