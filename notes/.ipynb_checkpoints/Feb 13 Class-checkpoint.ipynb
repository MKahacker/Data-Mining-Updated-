{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feb 13 \n",
    "page 119 to 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Went over supplement stuff including **software carpentry** and **Hacker Tools**\n",
    "\n",
    "Look for note books on *Blackboard* for classfication and decision trees \n",
    "\n",
    "To facilitate and test our predictions we can hold out some of our data and use it to predict the hold out data's attributes and test if your model predicts correctly. \n",
    "\n",
    "Homework 2 problems will generate random data and use two classes to train your model. Look at jupyter notebook on *Blackboard* for reference. Look at *Blobs notebook for random state(seeding)*. \n",
    "\n",
    "Space classifiers divide up sample spaces into regions and classify them by the majority of class attributes of the objects inside the region. Thus new values can be projected onto the space and a class attr can be predicted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers\n",
    "    (x,y) where x -> **BLACKBOX** -> y(or y hat) because its based on sample\n",
    "    f (the **BLACKBOX**)\n",
    "        - Parametric (linear regression) takes input and says yes or no\n",
    "            - parametric looks like function -> $b_1(x_1) + b_2(x_2)....$\n",
    "            - $(1/2)sum(y - y')^2$ tells the difference of regression classifier (also know as **squared error**)\n",
    "        - Nonparametric KNN handles many more classes than regression.\n",
    "            - $sum(y, y')$ than if it is 1 than correct if 0 then wrong. (Called **misclassifier error**)\n",
    "            - KNN looks at closets neighbor and looks at probrability.\n",
    "                $K_1/K$ compared to $K_2/K$ and use the class with the highest data. K is the number of neighbors and K_i is the number of neighbors in class i. \n",
    "            - If the predicted data set is too far away than nonparametric functions fail\n",
    "            - Nonparametric is good at capturing local structure and doesn't extend to data outside the data set\n",
    "            - Works for discrete and has to store a maping of all the data in the space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of parametric (regression)\n",
    "    - its compressed because of function\n",
    "    - has a larger data space. \n",
    "    - Explicitly shows relation through equation of Y from X.\n",
    "    - Classifiers use probability of certain objects being in class as contrast (they use probability).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to predict your classifiers behaviour. Basically not treating it as a Blackbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting/Training f\n",
    "--> sample  data: D\n",
    "we divided D into train(in sample) and test(out of sample)\n",
    "objects $x_1 to x_m$ are in sample while $x_(m+1) to x_n$ is out\n",
    "\n",
    "$f_training$ -> error meaing the trained function will have error \n",
    "so we use E(error) by using $f_test$ to look at the error that the model generates on the out of sample (test) data.\n",
    "\n",
    "The test error is the real error that we will probably see in the real world. \n",
    "\n",
    "The model's error on the test data is what matters in the real world.\n",
    "\n",
    "using a static split like ($x_1 to x_m$ are in sample while $x_(m+1) to x_n$ is out) leads to point estimation.\n",
    "\n",
    "A better model is **cross-validation** which takes a number k where that is the size of test set. We basically take the kth number to go into the test set. (n-k data goes into the training set). cross-validation aims to take k-1 elements and then take k and then repeat until they get to the end of the data set.\n",
    "\n",
    "k = n means that the test set -> 1 and the training set -> n-1. this means that the variance is very high. \n",
    "\n",
    "**stratified sampling** when your training and test sets are not proportionally representative. Don't have the same proportion of the population for example the training set has a high number of C1 compared to C2 while the test has a equal number of C1 and C2. \n",
    "\n",
    "**Bootstrap** if i have n samples probability is $1/n$ probality of not is $(1-1/n)^n$ . $lim n->inf(1 -(1-1/n)^n)$ is $1- 1/e$ is 63.2%. thus train is 2/3s and test is 1/3 of the data set. **Bootstrap** doesn't randomize it just grabs 1/3 2/3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "    - series of questions -> hierarchy (if statements and decision)\n",
    "                            \n",
    "                   <-yes   Q1(income < 100k) no-> \n",
    "                No cc                       Q3\n",
    "                                     Q6            Q7\n",
    "    - Leaf, root, and internal parts\n",
    "    - class assigned\n",
    "        - Terminal (leaf) assigns a specific class\n",
    "            - concludes class\n",
    "            - majority vote based on sample data. if our sample data has a prevelance of attributes related to objects than the vote determines the current object.\n",
    "                - There are probabilities based on the sample data. \n",
    "                - That is how leaves make decisions. \n",
    "        - Non-Terminal\n",
    "        \n",
    "**You don't fit a classifier with new input data. You always use your base data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms \n",
    "\n",
    "- Hunt's (1962) Binary Classifier.\n",
    "- Quinlan ID3 (1979)\n",
    "- Quinlan C4.5 (1993)\n",
    "- Breimann CART (1984)\n",
    "- C4.5 and CART are the state of the art decision trees.\n",
    "\n",
    "CART uses binary splits. It is very powerful. \n",
    "\n",
    "Hunt's algorithm: \n",
    "\n",
    "At node t (any node in the tree) \n",
    "    - Dt = {x_i, x_j ... x_k} (data that made it to the node)\n",
    "    if x in Dt and C(x) = y -> leaf node than the class is (y)\n",
    "    \n",
    "recursive definition is if x in Dt and C(x_i) != C(x_j) -> **split**\n",
    "\n",
    "If all the data is same class than decision is easy and any data just gets assigned class y.\n",
    "\n",
    "If there is more than one class than we binary split. Split divides two of the attributes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set\n",
    "(we usual sneak in )validation set -> 80% is training and validation\n",
    "Test set -> 20%\n",
    "\n",
    "Validation is where you do k-fold **cross validation** and other functions that are needed to make model better. \n",
    "\n",
    "The key is that validation data might be seen multiple times while test data will never be seen. \n",
    "\n",
    "You can use the validation data to try different models and choose the best one.\n",
    "\n",
    "The true performance will ofcourse come from the 20% test set. \n",
    "\n",
    "**Hyperparameters**: meta data that you put from outside the model. they are accessory parameters that help the model do prediction, like the maximum depth of the decision tree, or the weights in a linear regression. **parameters** of a model are **endogenous** the sample data determines these parameters. \n",
    "\n",
    "**Grid search** helps in establishing hyperparameters \n",
    "\n",
    "**Dask**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hunt's Split (attribute test conditions)\n",
    "\n",
    "    - which feature?\n",
    "    - what threshold?\n",
    "        - Binary value (easy to do split) / Binomial\n",
    "        - Nominal/multinomial -> if i have k possible values than I end up $2^(k-1)$ splits if R,G,B than $2^2$\n",
    "        - Ordinal a rank ordering and then treat as nominal/multinomial\n",
    "            - Example (A, B, C,....F) then A > B ... I then treat a nominal.\n",
    "        - Continous/Ratio -> we need a threshold for this one\n",
    "            - Example GPA 4.0 .... 0.0 (infinite in nature) \n",
    "            - Sample data has gaps. For example you have 3.79 and 3.50 you can take mid points and then divided into sets of 3.79 and neighbors and 3.50 and neighbors.\n",
    "\n",
    "**Perform this \"test\" for all features, all possible splits**\n",
    "Splits are basically partitions on a set of values in memory.\n",
    "\n",
    "    - which feature/threshold is picked?\n",
    "        we have a metric to compare the quality of a split\n",
    "        \n",
    "        start with a node with a 100 data points called parent.\n",
    "        it has two childern. \n",
    "        First we split with feature 1. We go through all possible income values and pick one lets say less than 100k\n",
    "        then one child is positive and has a probability of 49/50 for no and 1/50 yes\n",
    "        The other child is negative and has a probability of 45/50 for yes 5/50 no.\n",
    "        Child one had half of the data with less than a 100k\n",
    "        Child two had half of the data with 100k or greater income\n",
    "        We than look at **purity**\n",
    "\n",
    "**Purity**/**impurity** we want lower impurity and higher purity in child nodes.\n",
    "\n",
    "    Lets say our second split is on credit score. based on great than 600. \n",
    "    One child has 1/4 of the data set and has probility of 15/25 no and 10/35 yes\n",
    "    child two has 3/4 of the data and 50/75 yes and 25/75 yes\n",
    "    \n",
    "We see that the income split looks more cleaner. The child data follows a better dominance. Basically making one more positive and one more negative. \n",
    "\n",
    "**Purity** is measure by:\n",
    "    **entropy**: $-sum(p(i|t))(log_2)(p(i|t)) where p(i|t) = fraction of i at node t. with k classes in the data set. look in tan for specific formula page 67 and 68 and page 128. **entropy** is most pure at 0 when there is just one class\n",
    "    **Gini**: if you have a pure node **Gini** is zero. (page 128) for formula\n",
    "    **Missclassification error**: page 128 for formula\n",
    "        The class that you got wrong the most. \n",
    "\n",
    "When 50/50 dist in each child **entropy** is at 1 **gini** is at 1/2 and misclassification is also 1/2. Which means that a 50/50 dist is the worst split you can do on a tree.\n",
    "\n",
    "In our decision tree if we reach a pure node than it is a leaf and we assign a class.\n",
    "\n",
    "If not we have to split and add a new parameter. \n",
    "\n",
    "**Gain**: or net **Gain** the impurity(parent) - $sum Ni/N (I(v_j))$ look at page 129 for child purity. \n",
    "\n",
    "Since parent impurity is constant we want to minimize entropy of childern to maximize gain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example\n",
    "\n",
    "   N1    N2   N3\n",
    "   \n",
    "c1  0     1     3\n",
    "\n",
    "c2  6     5     3\n",
    "\n",
    "N1\n",
    "entropy = 0\n",
    "gini = 0\n",
    "miss = 0\n",
    "\n",
    "N2 \n",
    "entropy = $-1/6 log_2(1/6) - 5/6 log_2(5/6) = 2/3$\n",
    "gini = $1- (1/6)^2 + 1-(5/6)^2 = 1/3$\n",
    "miss = $1 - max [1/6, 5/6] = 1/6$\n",
    "\n",
    "N3\n",
    "entropy = 1\n",
    "g = 1/2\n",
    "miss = 1/2\n",
    "\n",
    "so the obvious split is N3 which will minimize entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Greedy** \n",
    "We cannot look at all the splits so we have to do a greedy approach. We choose split 1 and then split 2. We never check if split 2 was done first and then 1 what would happen. We always take the best split not accounting for future splits. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gain ratio** makes absolute values should use to compare apples to apples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we use decision trees? (Page 140 to 147)\n",
    "Likes\n",
    "    - nonparametric\n",
    "        - don't make assumption can throw at tree at anything\n",
    "    - Single decision trees are easy to read.\n",
    "    - Robust you can but anything in there like Bill Gates data. \n",
    "    - minimal preprocessing don't need to filter data and reduce dimensionality\n",
    "Dislikes\n",
    "    - nonparametric\n",
    "        - don't get parameters which are very useful\n",
    "    - Optimal DT is NP hard\n",
    "    - Fragmentation and sparsity -> depth. The more depth the sparser it gets.\n",
    "    - subtree replication the same split happens over and over because you didn't make it the first time\n",
    "        - not splitting by income in the begining and being forced to do it later\n",
    "    - Rectilinear (Axis-Parallel) \n",
    "        - we can only draw lines that are parallel to our feature axis\n",
    "        - No way to deal with circular data needs to draw squares\n",
    "        - also cannot deal with diagnol splits. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "we want low bias and low variance\n",
    "\n",
    "if E|y - y'| = 0 meaning zero error in reality we need to minimize\n",
    "\n",
    "if we have a similar model but we have two different variations of data than there should be no change in different predictions. \n",
    "\n",
    "Decision tree are high variance and low bias\n",
    "    - the decision tree is able to fit the training data perfectly.\n",
    "\n",
    "Random Forest are \"Higher\" bias but \"Lower\" variance\n",
    "\n",
    "Error to number of nodes look at 151. \n",
    "Generaly the training error goes lower but the testing error will go higher and higher. This is due to the trees adapting to local structure.\n",
    "\n",
    "**Pruning** only when working with one tree\n",
    "    - Pre: Early stop to stop the tree after a certain depth.\n",
    "    - Post: raise/replace a sub tree. When a subtree leads to the same conclusion you can replace the subtree with one node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance can be done by Random Forests to tell you which features split the best and thus the important features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always read the docs for decision trees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
